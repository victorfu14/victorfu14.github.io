---
layout: post
title:  EECS 550, Infomation Theory
categories: Maths
excerpt: So many noise, but I only want to hear you
published: true 
---

Because why not? Information theory sounds like a very cool name. And the person who laid groundwork for this discipline, Claude Shannon, is a Michigan alumnus.

Jokes aside, I just feel there is a lot to say about information. Like how we dig up distribution properties from real world datasets such as CIFAR10, how we estimate how much accuracy we can get when we need to preserve certain level of differential privacy, etc. I know it was mostly used in communications, but it is going to be useful anywhere now.

So we should start.

- [fixed length to fixed length block (FFB) codes](../../../../parts/information/information.pdf#section.1.1)
- [Shannon-McMillian Theorem](../../../../parts/information/information.pdf#section.1.2)
- [fixed length to variable length block (FVB) codes](../../../../parts/information/information.pdf#section.1.3)
- [coding theorem for FVB prefix codes, Huffman code](../../../../parts/information/information.pdf#section.1.4)
